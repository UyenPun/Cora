{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhH0v_bwUrXp"
   },
   "source": [
    "# Machine learning pipelines: Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_DB = \"neo4j\"\n",
    "NEO4J_AUTH = (\n",
    "    \"neo4j\",\n",
    "    \"12345678\",\n",
    ")\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oDE2LqTXAmy8"
   },
   "source": [
    "## Loading the Cora dataset\n",
    "\n",
    "The CSV files can be found at the following URIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORA_CONTENT = (\n",
    "    \"https://raw.githubusercontent.com/neo4j/graph-data-science/master/test-utils/src/main/resources/cora.content\"\n",
    ")\n",
    "CORA_CITES = (\n",
    "    \"https://raw.githubusercontent.com/neo4j/graph-data-science/master/test-utils/src/main/resources/cora.cites\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon loading, we need to perform an additional preprocessing step to convert the `subject` field (which is a string in the dataset) into an integer, because node properties have to be numerical in order to be projected into a graph; \n",
    "\n",
    "We also select a number of nodes to be held out to test the model after it has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_TO_ID = {\n",
    "    \"Neural_Networks\": 0,\n",
    "    \"Rule_Learning\": 1,\n",
    "    \"Reinforcement_Learning\": 2,\n",
    "    \"Probabilistic_Methods\": 3,\n",
    "    \"Theory\": 4,\n",
    "    \"Genetic_Algorithms\": 5,\n",
    "    \"Case_Based\": 6,\n",
    "}\n",
    "\n",
    "HOLDOUT_NODES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the CSV files using the `LOAD CSV` Cypher statement and some basic data transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a string representation of the SUBJECT_TO_ID map using backticks\n",
    "subject_map = json.dumps(SUBJECT_TO_ID).replace('\"', \"`\")\n",
    "\n",
    "# Cypher command to load the nodes using `LOAD CSV`, taking care of\n",
    "# converting the string `subject` field into an integer and\n",
    "# replacing the node label for the holdout nodes\n",
    "load_nodes = f\"\"\"\n",
    "    LOAD CSV FROM \"{CORA_CONTENT}\" AS row\n",
    "    WITH \n",
    "      {subject_map} AS subject_to_id,\n",
    "      toInteger(row[0]) AS extId, \n",
    "      row[1] AS subject, \n",
    "      toIntegerList(row[2..]) AS features\n",
    "    MERGE (p:Paper {{extId: extId, subject: subject_to_id[subject], features: features}})\n",
    "    WITH p LIMIT {HOLDOUT_NODES}\n",
    "    REMOVE p:Paper\n",
    "    SET p:UnclassifiedPaper\n",
    "\"\"\"\n",
    "\n",
    "# Cypher command to load the relationships using `LOAD CSV`\n",
    "load_relationships = f\"\"\"\n",
    "    LOAD CSV FROM \"{CORA_CITES}\" AS row\n",
    "    MATCH (n), (m) \n",
    "    WHERE n.extId = toInteger(row[0]) AND m.extId = toInteger(row[1])\n",
    "    MERGE (n)-[:CITES]->(m)\n",
    "\"\"\"\n",
    "\n",
    "# Load nodes and relationships on Neo4j\n",
    "gds.run_cypher(load_nodes)\n",
    "gds.run_cypher(load_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmFOLcCunfXB"
   },
   "source": [
    "With the data loaded on Neo4j, we can now project a graph including all the nodes and the `CITES` relationship as undirected (and with `SINGLE` aggregation, to skip repeated relationships as a result of adding the inverse direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projected graph containing both classified and unclassified nodes\n",
    "G, _ = gds.graph.project(\n",
    "    \"cora-graph\",\n",
    "    {\"Paper\": {\"properties\": [\"features\", \"subject\"]}, \"UnclassifiedPaper\": {\"properties\": [\"features\"]}},\n",
    "    {\"CITES\": {\"orientation\": \"UNDIRECTED\", \"aggregation\": \"SINGLE\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGWiTTrGN-Be"
   },
   "source": [
    "## Pipeline catalog basics\n",
    "\n",
    "Once the dataset has been loaded, we can define a node classification machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "node_pipeline, _ = gds.beta.pipeline.nodeClassification.create(\"cora-pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the pipeline has actually been created with the `list` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineInfo</th>\n",
       "      <th>pipelineName</th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>creationTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'featurePipeline': {'nodePropertySteps': [], ...</td>\n",
       "      <td>cora-pipeline</td>\n",
       "      <td>Node classification training pipeline</td>\n",
       "      <td>2023-05-15T00:57:55.790832600+07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pipelineInfo   pipelineName  \\\n",
       "0  {'featurePipeline': {'nodePropertySteps': [], ...  cora-pipeline   \n",
       "\n",
       "                            pipelineType                         creationTime  \n",
       "0  Node classification training pipeline  2023-05-15T00:57:55.790832600+07:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all pipelines\n",
    "gds.beta.pipeline.list()\n",
    "\n",
    "# Alternatively, get the details of a specific pipeline object\n",
    "gds.beta.pipeline.list(node_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Cil3MMlTtZ7L"
   },
   "source": [
    "## Configuring the pipeline\n",
    "\n",
    "We can now configure the pipeline. We need to:\n",
    "\n",
    "1. Select a subset of the available node properties to be used as features for the machine learning model\n",
    "1. Configure the train/test split and the number of folds for k-fold cross-validation _(optional)_\n",
    "1. Configure the candidate models for training\n",
    "1. Configure autotuning _(optional)_\n",
    "In this example we use Logistic Regression as a candidate model for the training, but other algorithms (such as Random Forest) are available as well. We also set some reasonable starting parameters that can be further tuned according to the needed metrics.\n",
    "\n",
    "Some hyperparameters such as `penalty` can be single values or ranges. If they are expressed as ranges, autotuning is used to search their best value.\n",
    "\n",
    "The `configureAutoTuning` method can be used to set the number of model candidates to try. Here we choose 5 to keep the training time short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                                     cora-pipeline\n",
       "nodePropertySteps                                                   []\n",
       "featureProperties                                           [features]\n",
       "splitConfig                {'testFraction': 0.2, 'validationFolds': 5}\n",
       "autoTuningConfig                                      {'maxTrials': 5}\n",
       "parameterSpace       {'MultilayerPerceptron': [], 'RandomForest': [...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Mark\" some node properties that will be used as features\n",
    "node_pipeline.selectFeatures([\"features\"])\n",
    "\n",
    "# If needed, change the train/test split ratio and the number of folds\n",
    "# for k-fold cross-validation\n",
    "node_pipeline.configureSplit(testFraction=0.2, validationFolds=5)\n",
    "\n",
    "# Add a model candidate to train\n",
    "node_pipeline.addLogisticRegression(maxEpochs=200, penalty=(0.0, 0.5))\n",
    "\n",
    "# Explicit set the number of trials for autotuning (default = 10)\n",
    "node_pipeline.configureAutoTuning(maxTrials=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qFIfl6yYXQgY"
   },
   "source": [
    "## Training the pipeline\n",
    "\n",
    "The configured pipeline is now ready to select and train a model. We also run a training estimate, to make sure there are enough resources to run the actual training afterwards.\n",
    "\n",
    "The Node Classification model supports several evaluation metrics. Here we use the global metric `F1_WEIGHTED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requiredMemory                                     [64 MiB ... 64 MiB]\n",
       "treeView             Memory Estimation: [64 MiB ... 64 MiB]\\r\\n|-- ...\n",
       "mapView              {'components': [{'components': [{'components':...\n",
       "bytesMin                                                      67130384\n",
       "bytesMax                                                      67162344\n",
       "nodeCount                                                         2698\n",
       "relationshipCount                                                10502\n",
       "heapPercentageMin                                                  0.1\n",
       "heapPercentageMax                                                  0.1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the resources needed for training the model\n",
    "node_pipeline.train_estimate(\n",
    "    G,\n",
    "    targetNodeLabels=[\"Paper\"],\n",
    "    modelName=\"cora-pipeline-model\",\n",
    "    targetProperty=\"subject\",\n",
    "    metrics=[\"F1_WEIGHTED\"],\n",
    "    randomSeed=42,\n",
    "    concurrency=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the actual training\n",
    "model, stats = node_pipeline.train(\n",
    "    G,\n",
    "    targetNodeLabels=[\"Paper\"],\n",
    "    modelName=\"cora-pipeline-model\",\n",
    "    targetProperty=\"subject\",\n",
    "    metrics=[\"F1_WEIGHTED\"],\n",
    "    randomSeed=42,\n",
    "    concurrency=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxYPHz6seMEn"
   },
   "source": [
    "We can inspect the result of the training, for example to print the evaluation metrics of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7287325951256631"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print F1_WEIGHTED metric\n",
    "stats[\"modelInfo\"][\"metrics\"][\"F1_WEIGHTED\"][\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QBEfXROYfNES"
   },
   "source": [
    "## Using the model for prediction\n",
    "\n",
    "After training, the model is ready to classify unclassified data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_mutate(\n",
    "    G,\n",
    "    mutateProperty=\"predictedClass\",\n",
    "    modelName=\"cora-pipeline-model\",\n",
    "    predictedProbabilityProperty=\"predictedProbabilities\",\n",
    "    targetNodeLabels=[\"UnclassifiedPaper\"],\n",
    ")\n",
    "\n",
    "predicted = gds.graph.streamNodeProperty(G, \"predictedClass\", [\"UnclassifiedPaper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeId</th>\n",
       "      <th>propertyValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodeId  propertyValue\n",
       "0       0              0\n",
       "1       1              5\n",
       "2       2              2\n",
       "3       3              2\n",
       "4       4              3\n",
       "5       5              5\n",
       "6       6              6\n",
       "7       7              0\n",
       "8       8              0\n",
       "9       9              4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeId</th>\n",
       "      <th>propertyValue</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodeId  propertyValue  subject\n",
       "0       0              0        0\n",
       "1       1              5        1\n",
       "2       2              2        2\n",
       "3       3              2        2\n",
       "4       4              3        3\n",
       "5       5              5        3\n",
       "6       6              6        4\n",
       "7       7              0        0\n",
       "8       8              0        0\n",
       "9       9              4        4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve node information from Neo4j using the node IDs from the prediction result\n",
    "nodes = gds.util.asNodes(predicted.nodeId.to_list())\n",
    "\n",
    "# Create a new DataFrame containing node IDs along with node properties\n",
    "nodes_df = pd.DataFrame([(node.id, node[\"subject\"]) for node in nodes], columns=[\"nodeId\", \"subject\"])\n",
    "\n",
    "# Merge with the prediction result on node IDs, to check the predicted value\n",
    "# against the original subject\n",
    "predicted.merge(nodes_df, on=\"nodeId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdEVypaiMc5d"
   },
   "source": [
    "## Writing result back to Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the predicted class written back to the graph, we can now write them back to the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writeMillis                        14\n",
       "graphName                  cora-graph\n",
       "nodeProperties       [predictedClass]\n",
       "propertiesWritten                  10\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.graph.nodeProperties.write(\n",
    "    G,\n",
    "    node_properties=[\"predictedClass\"],\n",
    "    node_labels=[\"UnclassifiedPaper\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plRCiikGOofd"
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "When the graph, the model and the pipeline are no longer needed, they should be dropped to free up memory. This only needs to be done if the Neo4j or AuraDS instance is not restarted, since a restart would clean up all the in-memory content anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.drop()\n",
    "model_fastrp.drop()\n",
    "node_pipeline.drop()\n",
    "node_pipeline_fastrp.drop()\n",
    "\n",
    "G.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neo4j database instead needs to be cleaned up explicitly if no longer useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"MATCH (n) WHERE n:Paper OR n:UnclassifiedPaper DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to close the client as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
